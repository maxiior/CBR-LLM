{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maciej/anaconda3/envs/ml_lm/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import regex #dev\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "from langchain_community.embeddings import GPT4AllEmbeddings\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "def score_bleu(pred:str, y:str, type=2): \n",
    "    if type == 4:\n",
    "        weights = [0.25, 0.25, 0.25, 0.25]\n",
    "    elif type == 3:\n",
    "        weights = [0.33, 0.33, 0.33]\n",
    "    elif type == 2:\n",
    "        weights = [0.5, 0.5]\n",
    "    res = []\n",
    "    for xe, ye in zip(pred, y):\n",
    "        res.append(sentence_bleu([list(xe)], list(ye), weights))\n",
    "    \n",
    "    return np.average(res)\n",
    "    \n",
    "def _embedding_cosine_similarity(x:str, y:str, embedding_fun) -> float:\n",
    "    X = embedding_fun.embed_query(x)\n",
    "    Y = embedding_fun.embed_query(y)\n",
    "    return cosine_similarity([X], [Y])\n",
    "\n",
    "def embedding_cosine_similarity(x:str, y:str, embedding_fun) -> float:\n",
    "    res = []\n",
    "    for xe, ye in zip(x, y):\n",
    "        res.append(_embedding_cosine_similarity(xe, ye, embedding_fun))\n",
    "    return np.average(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "\n",
    "def validate(val_file, pred_file, emb_fun):\n",
    "    dfy = pd.read_csv(val_file)\n",
    "    dfg = pd.read_csv(pred_file)\n",
    "\n",
    "    dfy = dfy[:1000]\n",
    "    dfg = dfg[:1000]\n",
    "\n",
    "    y = dfy.steps.values\n",
    "    # y = dfy.response.values\n",
    "    pred = dfg.response.values\n",
    "\n",
    "    bl2 = score_bleu(y, pred, 2)\n",
    "    bl3 = score_bleu(y, pred, 3)\n",
    "    bl4 = score_bleu(y, pred, 4)\n",
    "    cosim = embedding_cosine_similarity(y, pred, emb_fun)\n",
    "    pprint(\n",
    "        {\n",
    "            \"dataset\": pred_file,\n",
    "            \"cosim\" : cosim,\n",
    "            \"bleu_2\" : bl2,\n",
    "            \"bleu_3\" : bl3,\n",
    "            \"bleu_4\" : bl4,\n",
    "        }\n",
    "    )\n",
    "    return bl2, bl3, bl4, cosim\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert_load_from_file: gguf version     = 2\n",
      "bert_load_from_file: gguf alignment   = 32\n",
      "bert_load_from_file: gguf data offset = 695552\n",
      "bert_load_from_file: model name           = BERT\n",
      "bert_load_from_file: model architecture   = bert\n",
      "bert_load_from_file: model file type      = 1\n",
      "bert_load_from_file: bert tokenizer vocab = 30522\n"
     ]
    }
   ],
   "source": [
    "emb_fun = GPT4AllEmbeddings()\n",
    "# emb_fun = HuggingFaceEmbeddings(model_name=\"BAAI/bge-large-en-v1.5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu_2': 0.5195513088029691,\n",
      " 'bleu_3': 0.43677706291221,\n",
      " 'bleu_4': 0.3666542954343745,\n",
      " 'cosim': 0.7454890563329896,\n",
      " 'dataset': 'validation_cbr_00_results.csv'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "VAL = \"_validation_half.csv\"\n",
    "# PE = \"validation_pe2_results.csv\"\n",
    "CBR = \"validation_cbr_00_results.csv\"\n",
    "# CBR_ING = \"small_validation_cbr_00_ing_results_p.csv\"\n",
    "# OLD_CBR = \"old_small_validation_cbr_00_results_p.csv\"\n",
    "# CBR_NAM = \"small_validation_cbr_00_nam_results_p.csv\"\n",
    "# CBR_LARGE = \"small_validation_cbr_00_large_half_results_p.csv\"\n",
    "\n",
    "# validate(VAL, PE, emb_fun)\n",
    "validate(VAL, CBR, emb_fun)\n",
    "# validate(VAL, CBR_ING, emb_fun)\n",
    "# validate(VAL, CBR_NAM, emb_fun)\n",
    "# validate(VAL, CBR_LARGE, emb_fun)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bleu_2': 0.5303783219506372,\n",
       " 'bleu_3': 0.4462962309433792,\n",
       " 'bleu_4': 0.3753365885749213,\n",
       " 'cosim': 0.7618514457651429,\n",
       " 'dataset': 'validation_pe2_results.csv'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1000 samples - LLama 7B\n",
    "\n",
    "{'bleu_2': 0.5303783219506372,\n",
    " 'bleu_3': 0.4462962309433792,\n",
    " 'bleu_4': 0.3753365885749213,\n",
    "        'cosim': 0.7618514457651429,\n",
    " 'dataset': 'validation_pe2_results.csv'}\n",
    "{'bleu_2': 0.5195513088029691,\n",
    " 'bleu_3': 0.43677706291221,\n",
    " 'bleu_4': 0.3666542954343745,\n",
    "        'cosim': 0.7454890563329896,\n",
    " 'dataset': 'validation_cbr_00_results.csv'}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 1000 samples\n",
    "\n",
    "{'bleu_2': 0.5396068827158336,\n",
    " 'bleu_3': 0.45617526600881114,\n",
    " 'bleu_4': 0.38571558598671957,\n",
    "        'cosim': 0.7725588565018909,\n",
    " 'dataset': 'small_validation_pe_results_p.csv'}\n",
    "\n",
    "{'bleu_2': 0.542812939755022,\n",
    " 'bleu_3': 0.45964949518984566,\n",
    " 'bleu_4': 0.38905272937763996,\n",
    "        'cosim': 0.7654708413731175,\n",
    " 'dataset': 'small_validation_cbr_00_results_p.csv'}\n",
    "\n",
    "{'bleu_2': 0.5513406686475593,\n",
    " 'bleu_3': 0.4653106822819303,\n",
    " 'bleu_4': 0.39302688807601166,\n",
    "        'cosim': 0.7632422508541131,\n",
    " 'dataset': 'small_validation_cbr_00_ing_results_p.csv'}\n",
    "\n",
    "{'bleu_2': 0.5484066657634896,\n",
    " 'bleu_3': 0.46442737156905955,\n",
    " 'bleu_4': 0.3931165177905519,\n",
    "        'cosim': 0.7621681662680856,\n",
    " 'dataset': 'small_validation_cbr_00_nam_results_p.csv'}\n",
    "\n",
    "{'bleu_2': 0.5509298184714941,\n",
    " 'bleu_3': 0.4681376893134645,\n",
    " 'bleu_4': 0.39796219635868374,\n",
    "       'cosim': 0.7685492702758651,\n",
    " 'dataset': 'small_validation_cbr_00_large_half_results_p.csv'}\n",
    "\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 500 samples\n",
    "\n",
    "{'bleu_2': 0.5426869728805064,\n",
    " 'bleu_3': 0.458388462134935,\n",
    " 'bleu_4': 0.3874877600270263,\n",
    " 'cosim': 0.7707031342117534,\n",
    " 'dataset': 'small_validation_pe_results_p.csv'}\n",
    "\n",
    "{'bleu_2': 0.5438659346908847,\n",
    " 'bleu_3': 0.46062494514966273,\n",
    " 'bleu_4': 0.38978623748374275,\n",
    " 'cosim': 0.7669587393039417,\n",
    " 'dataset': 'small_validation_cbr_00_results_p.csv'}\n",
    "\n",
    "{'bleu_2': 0.54496451882725,\n",
    " 'bleu_3': 0.4593921251448247,\n",
    " 'bleu_4': 0.38765187507372423,\n",
    " 'cosim': 0.7590582257581593,\n",
    " 'dataset': 'small_validation_cbr_00_ing_results_p.csv'}\n",
    "\n",
    "{'bleu_2': 0.5460347176785251,\n",
    " 'bleu_3': 0.4617148488887874,\n",
    " 'bleu_4': 0.39058422725089476,\n",
    " 'cosim': 0.7601030492891336,\n",
    " 'dataset': 'small_validation_cbr_00_nam_results_p.csv'}\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding_fun = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "# embedding_fun = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L12-v2\")\n",
    "# embedding_fun = HuggingFaceEmbeddings(model_name=\"sentence-transformers/paraphrase-MiniLM-L6-v2\")\n",
    "# embedding_fun = HuggingFaceEmbeddings(model_name=\"BAAI/bge-large-en-v1.5\")\n",
    "# embedding_fun = GPT4AllEmbeddings()\n",
    "# embedding_fun = HuggingFaceEmbeddings()\n",
    "\n",
    "# model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "# len(embedding_fun.embed_query(\"sdf\"))\n",
    "# len(model.encode(\"asd\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding_cosine_similarity(y, pred, GPT4AllEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPE -----\\nembedding_sim: 0.77055\\nembedding_sim_pf: 0.72920\\nHuggingFaceEmbeddings: 0.82272\\nbl2: 0.54114\\nbl3: 0.45684\\nbl4: 0.38604\\n\\nCBR_00 -----\\nembedding_sim: 0.76286\\nembedding_sim_pf: 0.72389\\nHuggingFaceEmbeddings: 0.81547\\nbl2: 0.54043\\nbl3: 0.45686\\nbl4: 0.38614\\n\\nCBR_00_ing -----\\nembedding_sim: 0.76121\\nbl2: 0.54747\\nbl3: 0.46198\\nbl4: 0.39026\\n\\n\\nCBR_00 -----\\nembedding_sim: 0.\\nbl2: 0.\\nbl3: 0.\\nbl4: 0.\\n\\n\\nold_CBR_00 -----\\nembedding_sim: 0.75980\\nbl2: 0.52887\\nbl3: 0.44601\\nbl4: 0.37680\\n\\n\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "PE -----\n",
    "embedding_sim: 0.77055\n",
    "embedding_sim_pf: 0.72920\n",
    "HuggingFaceEmbeddings: 0.82272\n",
    "bl2: 0.54114\n",
    "bl3: 0.45684\n",
    "bl4: 0.38604\n",
    "\n",
    "CBR_00 -----\n",
    "embedding_sim: 0.76286\n",
    "embedding_sim_pf: 0.72389\n",
    "HuggingFaceEmbeddings: 0.81547\n",
    "bl2: 0.54043\n",
    "bl3: 0.45686\n",
    "bl4: 0.38614\n",
    "\n",
    "CBR_00_ing -----\n",
    "embedding_sim: 0.76121\n",
    "bl2: 0.54747\n",
    "bl3: 0.46198\n",
    "bl4: 0.39026\n",
    "\n",
    "\n",
    "CBR_00 -----\n",
    "embedding_sim: 0.\n",
    "bl2: 0.\n",
    "bl3: 0.\n",
    "bl4: 0.\n",
    "\n",
    "\n",
    "old_CBR_00 -----\n",
    "embedding_sim: 0.75980\n",
    "bl2: 0.52887\n",
    "bl3: 0.44601\n",
    "bl4: 0.37680\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_lm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
